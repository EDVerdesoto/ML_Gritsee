# GuÃ­a de Uso - Sistema de Descarga y GestiÃ³n de ImÃ¡genes

## ğŸ“ Archivos del Sistema

1. **descarga_archivos.py** - Script principal de descarga
2. **limpiar_duplicados.py** - Limpiador de duplicados por hash SHA256
3. **verificar_con_csv.py** - Verificador de completitud

---

## ğŸ”„ Flujo de Trabajo Recomendado

### Escenario 1: Limpiar Duplicados Existentes

Si ya tienes imÃ¡genes descargadas con duplicados (~700 en tu caso):

```bash
# 1. Limpiar duplicados (DRY-RUN primero - NO mueve archivos)
python3 limpiar_duplicados.py --dry-run

# 2. Si el resultado se ve bien, ejecutar la limpieza real
python3 limpiar_duplicados.py

# 3. Verificar completitud despuÃ©s de limpiar
python3 verificar_con_csv.py
```

### Escenario 2: Descarga Inicial o Re-descarga

Si estÃ¡s descargando por primera vez o quieres rehacer:

```bash
# 1. Ejecutar descarga (con numeraciÃ³n corregida)
python3 descarga_archivos.py

# 2. Verificar completitud
python3 verificar_con_csv.py

# 3. Si detectas duplicados (no deberÃ­a pasar), limpia
python3 limpiar_duplicados.py
```

---

## ğŸ“ Detalles de Cada Script

### `limpiar_duplicados.py`

**PropÃ³sito:** Encuentra y elimina imÃ¡genes duplicadas basÃ¡ndose en contenido (hash SHA256), no en nombres.

**IMPORTANTE:** Una misma imagen **DEBE** estar en mÃºltiples carpetas (burbujas, bordes, distribuciÃ³n, horneado, grasa) porque cada imagen tiene mÃºltiples clasificaciones. Esto NO son duplicados.

**Duplicados REALES:** Son imÃ¡genes con el **mismo contenido** y **diferentes nÃºmeros** en la **MISMA carpeta**.

**Ejemplo:**
```
âœ… NO ES DUPLICADO (comportamiento correcto):
   burbujas/si/Cumbres-9_15-175.png
   bordes/limpio/Cumbres-9_15-175.png
   distribucion/mala/Cumbres-9_15-175.png
   â†’ Misma imagen en diferentes categorÃ­as (CORRECTO)

âŒ SÃ ES DUPLICADO (error a corregir):
   burbujas/si/Cumbres-9_15-175.png
   burbujas/si/Cumbres-9_15-812.png
   â†’ Mismo contenido, misma carpeta, diferentes nÃºmeros (DUPLICADO)
```

**Funcionamiento:**
1. Escanea todas las imÃ¡genes y calcula hash SHA256 de cada una
2. Agrupa imÃ¡genes con el mismo contenido EN LA MISMA CARPETA
3. Para cada grupo de duplicados:
   - Lee el CSV correspondiente para determinar el rango vÃ¡lido (1 a N)
   - Identifica quÃ© imagen tiene el nÃºmero mÃ¡s bajo dentro del rango vÃ¡lido
   - Mueve las demÃ¡s a `DUPLICADOS/` (mantiene estructura de carpetas)

**Modo Dry-Run:**
```bash
python3 limpiar_duplicados.py --dry-run
```
- NO mueve archivos
- Solo muestra lo que harÃ­a
- Genera log de depuraciÃ³n

**Modo Real:**
```bash
python3 limpiar_duplicados.py
```
- Mueve archivos a `DUPLICADOS/`
- Genera `log_limpieza_duplicados.txt`

**Ejemplo de Log:**
```
[Cumbres-9_15] [burbujas/si] - Hash: abc123...
  Duplicados en la misma carpeta: 2
  CSV: Backup 9_15 9_21 EvaluaciÃ³n Pizzas HQ - Cumbres.csv
  Rango vÃ¡lido: 1 a 368
  âœ“ MANTENER: Cumbres-9_15-175.png (nÃºmero 175)
    UbicaciÃ³n: burbujas/si
  âœ— MOVER: Cumbres-9_15-812.png (nÃºmero 812, fuera de rango)
    Desde: burbujas/si
    â†’ DUPLICADOS/burbujas/si/
```

---

### `verificar_con_csv.py`

**PropÃ³sito:** Verifica que todas las imÃ¡genes esperadas segÃºn los CSVs estÃ©n descargadas y en las carpetas correctas.

**NumeraciÃ³n:** Cada imagen se numera segÃºn: `nÃºmero_imagen = fila_csv - 2`
- Fila 3 del CSV = imagen 1
- Fila 4 del CSV = imagen 2
- etc.

**Uso Interactivo:**
```bash
python3 verificar_con_csv.py
```

MostrarÃ¡ menÃº:
```
Archivos CSV encontrados: 5

  [1] Backup 9_15 9_21 EvaluaciÃ³n Pizzas HQ - Cumbres.csv
  [2] Backup 9_22 9_28 EvaluaciÃ³n Pizzas HQ - Cumbres.csv
  ...

Opciones:
  - Ingresa un nÃºmero para verificar un archivo especÃ­fico
  - Ingresa 'todos' para verificar todos
  - Ingresa '0' para salir
```

**Salida:**
- âœ… ImÃ¡genes completas: existen en todas las carpetas esperadas
- âš ï¸ ImÃ¡genes incompletas: existen pero faltan en algunas carpetas
- âŒ ImÃ¡genes faltantes: no existen en ninguna carpeta

---

### `descarga_archivos.py`

**PropÃ³sito:** Descarga imÃ¡genes desde URLs en CSVs y las clasifica en carpetas segÃºn atributos.

**NumeraciÃ³n Corregida:** 
- Cada CSV tiene numeraciÃ³n **independiente** empezando en 1
- Ya NO acumula nÃºmeros entre CSVs
- CSV 1: imÃ¡genes 1-250
- CSV 2: imÃ¡genes 1-180 (NO 251-430)

**CaracterÃ­sticas:**
- **Multi-threading:** 32 workers concurrentes
- **Reinicio inteligente:** Detecta CSVs ya descargados comparando imÃ¡genes existentes
- **LÃ­mite por carpeta:** 500 imÃ¡genes mÃ¡ximo en cada subcarpeta
- **Thread-safe:** Usa locks por carpeta para evitar race conditions
- **Progress bar:** Muestra velocidad de descarga en MB/s por imagen

**Estructura de Carpetas:**
```
BASE_DIR/
â”œâ”€â”€ burbujas/
â”‚   â”œâ”€â”€ si/
â”‚   â””â”€â”€ no/
â”œâ”€â”€ bordes/
â”‚   â”œâ”€â”€ limpio/
â”‚   â””â”€â”€ sucio/
â”œâ”€â”€ distribucion/
â”‚   â”œâ”€â”€ correcto/
â”‚   â”œâ”€â”€ aceptable/
â”‚   â”œâ”€â”€ media/
â”‚   â”œâ”€â”€ mala/
â”‚   â””â”€â”€ deficiente/
â”œâ”€â”€ horneado/
â”‚   â”œâ”€â”€ correcto/
â”‚   â”œâ”€â”€ alto/
â”‚   â”œâ”€â”€ bajo/
â”‚   â”œâ”€â”€ insuficiente/
â”‚   â””â”€â”€ excesivo/
â””â”€â”€ grasa/
    â”œâ”€â”€ si/
    â””â”€â”€ no/
```

---

## ğŸ” Entendiendo la NumeraciÃ³n

### Sistema Anterior (INCORRECTO)
```
CSV 1 (100 imÃ¡genes): Cumbres-9_15-1 a Cumbres-9_15-100
CSV 2 (80 imÃ¡genes):  Cumbres-9_22-101 a Cumbres-9_22-180  âŒ MALO
                      ^^^^^^^^^^^^^^^ 101-180 causÃ³ duplicados
```

### Sistema Actual (CORRECTO)
```
CSV 1 (100 imÃ¡genes): Cumbres-9_15-1 a Cumbres-9_15-100
CSV 2 (80 imÃ¡genes):  Cumbres-9_22-1 a Cumbres-9_22-80   âœ… CORRECTO
                      ^^^^^^^^^^^^^^^ Cada CSV empieza en 1
```

**FÃ³rmula:** `nÃºmero_imagen = Ã­ndice_fila + 1` (donde Ã­ndice empieza en 0)
- Fila 3 del CSV (Ã­ndice 0) â†’ imagen 1
- Fila 4 del CSV (Ã­ndice 1) â†’ imagen 2

---

## âš ï¸ Notas Importantes

1. **Backup antes de limpiar:** Aunque `limpiar_duplicados.py` mueve a `DUPLICADOS/`, considera hacer backup de `Descarga_Pizzas/` antes de la limpieza real.

2. **Dry-run es tu amigo:** Siempre ejecuta `--dry-run` primero para verificar quÃ© se va a hacer.

3. **Logs:** Revisa `log_limpieza_duplicados.txt` despuÃ©s de la limpieza para ver decisiones detalladas.

4. **Tiempo de ejecuciÃ³n:** Con ~2444 imÃ¡genes, el cÃ¡lculo de hashes puede tomar 2-5 minutos.

5. **CSVs en UTF-8:** AsegÃºrate que los CSVs estÃ©n en UTF-8 para evitar problemas de lectura.

---

## ğŸ› ResoluciÃ³n de Problemas

### "No se encontraron archivos CSV"
- Verifica que los CSVs estÃ©n en: `~/Practicas/Descarga de archivos/Archivos/`

### "No such file or directory: Descarga_Pizzas"
- Las imÃ¡genes deben estar en: `~/Practicas/Descarga_Pizzas/`
- Si la carpeta no existe, `descarga_archivos.py` la crea automÃ¡ticamente

### "Hash calculation taking too long"
- Normal para ~2500 imÃ¡genes (2-5 min)
- Si tarda mÃ¡s de 10 min, verifica que las imÃ¡genes sean PNG reales

### "Unexpected keyword argument 'expected_replacements'"
- Error en versiÃ³n anterior del cÃ³digo, ya corregido

---

## ğŸ“Š Ejemplo Completo

```bash
# SituaciÃ³n inicial: 2444 imÃ¡genes, ~700 duplicados

# Paso 1: Simular limpieza
python3 limpiar_duplicados.py --dry-run
# Output: "[DRY-RUN] Se moverÃ­an 700 imÃ¡genes a DUPLICADOS/"

# Paso 2: Limpiar
python3 limpiar_duplicados.py
# Output: "700 imÃ¡genes movidas a DUPLICADOS/"

# Paso 3: Verificar completitud
python3 verificar_con_csv.py
# Elegir opciÃ³n "todos"
# Output: "1744/1744 imÃ¡genes completas (100%)"

# Paso 4: Si faltara algo, re-descargar
python3 descarga_archivos.py
# Output: "CSV ya procesado, saltando..." (si todo estÃ¡ completo)
```

---

